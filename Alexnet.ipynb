{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alexnet.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf5fbWUy21Qr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('alexnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alexnet 구현\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "devices = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(devices)"
      ],
      "metadata": {
        "id": "84e--sW_qzta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transforms : 이미지 데이터를 로딩할 때 모듈의 입력값으로 사용할 수 있도록 변환한다.\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(227),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ])"
      ],
      "metadata": {
        "id": "USES0D-Lq9Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trans and Test set 로딩\n",
        "# 데이터로 CIFAR-10 사용\n",
        "\n",
        "trainset = datasets.CIFAR10('~/.data', download=True, train=True, transform =transform)\n",
        "trainset = torch.utils.data.DataLoader(trainset, batch_size = 256, shuffle = True)\n",
        "\n",
        "testset = datasets.CIFAR10('~/.data', download = True, train = False, transform = transform)\n",
        "testset = torch.utils.data.DataLoader(testset, batch_size = 256, shuffle = True)"
      ],
      "metadata": {
        "id": "mwEdXL5dWtAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구축\n",
        "class AlexNet(nn.Module):\n",
        "  def __init__(self, input_size = 227, num_classes = 10):\n",
        "    super(AlexNet, self).__init__()\n",
        "\n",
        "    self.cnnLayer = nn.Sequential(\n",
        "        \n",
        "        # 1st Conv : conv, relu, lrm, pool\n",
        "        # in_channels = 입력 채널 수, out_channels = 출력 채널 수, kernel_size = 필터 크기\n",
        "        nn.Conv2d(in_channels = 3, out_channels = 96, kernel_size = 11, padding = 0, stride = 4),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75, k=2), \n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 2), # 55 -> 27\n",
        "\n",
        "        # 2st Conv : conv, relu, lrm, pool\n",
        "\n",
        "        nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size = 5, padding = 2, stride = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75, k = 2),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
        "\n",
        "        # 3st Conv : conv, relu\n",
        "\n",
        "        nn.Conv2d(in_channels = 256, out_channels = 384, kernel_size = 3, padding = 1, stride = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "\n",
        "        # 4st Conv : cont, relu\n",
        "\n",
        "        nn.Conv2d(in_channels = 384, out_channels = 384, kernel_size = 3, padding = 1, stride = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "\n",
        "        # 5th Conv : conv, relu, lrm, pool\n",
        "        nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size = 3, padding = 1 , stride = 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75, k = 2),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
        "\n",
        "    )\n",
        "\n",
        "    self.fcLayer = nn.Sequential(\n",
        "        # FC Layer\n",
        "        nn.Linear(6*6*256, 4096),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(p = 0.5),\n",
        "\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(p = 0.5),\n",
        "        nn.Linear(4096, num_classes)\n",
        "\n",
        "    )\n",
        "    # 표준화 및 bias 초기화\n",
        "    for layer in self.cnnLayer:\n",
        "      if isinstance(layer, nn.Conv2d) :\n",
        "        # conv레이어들을 가우시안 분포로 표준화 하고 bias는 0\n",
        "        nn.init.normal_(layer.weight, mean = 0, std = 0.01)\n",
        "        nn.init.constant_(layer.bias, 0)\n",
        "\n",
        "    # 그런데 2,4,5 conv 는 1로 초기화\n",
        "    nn.init.constant_(self.cnnLayer[4].bias, 1)\n",
        "    nn.init.constant_(self.cnnLayer[10].bias, 1)\n",
        "    nn.init.constant_(self.cnnLayer[12].bias, 1)\n",
        "    \n",
        "  def forward(self, train):\n",
        "    # 멀티 GPU는 당장 불가능하기때문에 제외\n",
        "    output = self.cnnLayer(train)\n",
        "    output = output.view(-1, 256*6*6)\n",
        "    output = self.fcLayer(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "alexnet = AlexNet(277,10)\n",
        "alexnet.to(devices)\n",
        "\n",
        "# weight decay = 0.0005, momentum = 0.9, lr = 0.01\n",
        "optimizer = torch.optim.SGD(alexnet.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 0.0005)\n",
        "criterion = nn.CrossEntropyLoss().to(devices)\n",
        "\n"
      ],
      "metadata": {
        "id": "M1yxU7JRXeRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "from tqdm.notebook import tqdm\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  for data, classes in tqdm(trainset) :\n",
        "    inputs, labels = data.to(devices), classes.to(devices)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = alexnet(inputs)\n",
        "\n",
        "    # 순전파, 역전파 최적화\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  correct = list(0. for i in range(1000))\n",
        "  total = list(0. for i in range(1000))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, classes in testset:\n",
        "      inputs, labels = data.to(devices), classes.to(devices)\n",
        "      outputs = alexnet(inputs)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      c = (predicted == labels).squeeze()\n",
        "      for i in range(labels.size()[0]):\n",
        "        label = labels[i]\n",
        "        correct[label] += c[i].item()\n",
        "        total[label] += 1\n",
        "\n",
        "\n",
        "  print('{0} : loss {1:.3f}, val_acc {2:.3f}'.format(epoch+1, epoch_loss, (sum(correct) / sum(total))))"
      ],
      "metadata": {
        "id": "lY9zJ6c_yKSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}